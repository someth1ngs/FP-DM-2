{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit (Deployment)"
      ],
      "metadata": {
        "id": "hUtNmEAj7nzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "5FpDyChe7sVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QurNjEix7mU1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/streamlit.csv')\n",
        "\n",
        "# Ubah kolom target menjadi biner\n",
        "df['Kelayakan'] = df['Kelayakan'].map({'Tidak Layak': 0, 'Layak': 1})\n",
        "\n",
        "# Gabungkan semua kolom fitur menjadi satu kolom teks\n",
        "df['combined_text'] = df.iloc[:, :-1].astype(str).agg(' '.join, axis=1)\n",
        "\n",
        "# Pisahkan fitur dan target\n",
        "X = df['combined_text']  # Gabungan teks fitur\n",
        "y = df['Kelayakan']      # Kolom target\n",
        "\n",
        "# Vectorize data menggunakan TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(X)  # Hasil berupa matriks sparse\n",
        "\n",
        "# Simpan vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vec_file:\n",
        "    pickle.dump(vectorizer, vec_file)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Inisialisasi dan fit model SVC\n",
        "classifier = DecisionTreeClassifier(random_state=42)\n",
        "# classifier = SVC(kernel='linear')\n",
        "# classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluasi akurasi\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(f'Akurasi: {score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open(\"classifier.pkl\", \"wb\")\n",
        "pickle.dump(classifier, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "EfVQ_ThY7qOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import streamlit as st\n",
        "\n",
        "# Load model dan vectorizer\n",
        "pickle_in = open('classifier.pkl', 'rb')\n",
        "classifier = pickle.load(pickle_in)\n",
        "\n",
        "pickle_vectorizer = open('tfidf_vectorizer.pkl', 'rb')\n",
        "vectorizer = pickle.load(pickle_vectorizer)\n",
        "\n",
        "# Load data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('/content/streamlit.csv')  # Ganti dengan file Anda\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Fungsi prediksi\n",
        "def prediction(title, company, location, salary):\n",
        "    # Gabungkan input dalam satu string atau array\n",
        "    user_input = f\"{title} {company} {location} {salary}\"\n",
        "\n",
        "    # Transform input menggunakan TF-IDF\n",
        "    input_vectorized = vectorizer.transform([user_input])\n",
        "\n",
        "    # Prediksi menggunakan model\n",
        "    prediction = classifier.predict(input_vectorized)\n",
        "\n",
        "    # Kembalikan hasil prediksi\n",
        "    job_map = {0: 'Tidak Layak', 1: 'Layak'}\n",
        "    job_name = job_map[prediction[0]]\n",
        "    return job_name\n",
        "\n",
        "# Main app\n",
        "def main():\n",
        "    st.title('Prediksi Kelayakan Kandidat Kerja')\n",
        "\n",
        "    # Membuat dropdown dengan variasi unik dari data\n",
        "    title_options = df['Title'].unique()\n",
        "    company_options = df['Company'].unique()\n",
        "    location_options = df['Location'].unique()\n",
        "    salary_options = df['Salary'].unique()\n",
        "\n",
        "    # Dropdown untuk input\n",
        "    title = st.selectbox('Pilih Title', title_options)\n",
        "    company = st.selectbox('Pilih Company', company_options)\n",
        "    location = st.selectbox('Pilih Location', location_options)\n",
        "    salary = st.selectbox('Pilih Salary', salary_options)\n",
        "\n",
        "    result = \"\"\n",
        "\n",
        "    if st.button('Prediksi'):\n",
        "        result = prediction(title, company, location, salary)\n",
        "    st.success(result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "YF2ZJ__j7ujC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "m7bcIau77vx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "eRPBB_yQ7wqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}